# üï∑Ô∏è H∆Ø·ªöNG D·∫™N WEB SCRAPING FULL CONTENT

## ‚ú® T√çNH NƒÇNG M·ªöI

**V·∫•n ƒë·ªÅ:** RSS feeds th∆∞·ªùng ch·ªâ c√≥ excerpt/summary (50-200 t·ª´), kh√¥ng ƒë·ªß cho b√†i vi·∫øt ƒë·∫ßy ƒë·ªß.

**Gi·∫£i ph√°p:** Web Scraping t·ª± ƒë·ªông crawl **FULL CONTENT** t·ª´ URL g·ªëc!

---

## üöÄ C√ÅCH S·ª¨ D·ª§NG

### B∆∞·ªõc 1: Truy c·∫≠p RSS Management

```
http://localhost:3001/admin/rss
```

### B∆∞·ªõc 2: B·∫≠t Web Scraping

T√¨m ph·∫ßn **"üï∑Ô∏è Web Scraping Options"** (box m√†u t√≠m):

```
‚òëÔ∏è L·∫•y to√†n b·ªô n·ªôi dung b√†i vi·∫øt (Scrape full article content)
```

‚úÖ **Tick v√†o checkbox n√†y**

### B∆∞·ªõc 3: Fetch RSS Feed

Click n√∫t **"Fetch"** (‚ü≥) b√™n c·∫°nh feed b·∫•t k·ª≥.

**Qu√° tr√¨nh:**
```
1. Fetch RSS feed (1-2s)
2. Parse items (instant)
3. üï∑Ô∏è Scrape m·ªói b√†i vi·∫øt (5-15s/b√†i)
   ‚îú‚îÄ Fetch HTML t·ª´ URL g·ªëc
   ‚îú‚îÄ Parse v·ªõi Mozilla Readability
   ‚îú‚îÄ Extract article content
   ‚îú‚îÄ Convert HTML ‚Üí Markdown
   ‚îî‚îÄ Extract main image
4. Save to database
```

**Th·ªùi gian:**
- **Kh√¥ng scrape:** ~5-10s (10 b√†i)
- **C√≥ scrape:** ~1-3 ph√∫t (10 b√†i)

### B∆∞·ªõc 4: Xem K·∫øt Qu·∫£

```
‚úÖ Import th√†nh c√¥ng!
Feed: VnExpress - C√¥ng ngh·ªá
T·ªïng s·ªë items: 20
B√†i vi·∫øt m·ªõi: 10
ƒê√£ b·ªè qua: 10
```

**V√†o "B·∫£n nh√°p"** ‚Üí Th·∫•y b√†i vi·∫øt v·ªõi:
- ‚úÖ N·ªôi dung FULL (1000-3000 t·ª´)
- ‚úÖ Images ch·∫•t l∆∞·ª£ng cao
- ‚úÖ Author name (n·∫øu c√≥)
- ‚úÖ Format Markdown ƒë·∫πp

---

## üìä SO S√ÅNH

### RSS Only (Kh√¥ng Scrape)

```markdown
**N·ªôi dung:**
C√¥ng ngh·ªá AI ƒëang ph√°t tri·ªÉn nhanh ch√≥ng. 
C√°c ·ª©ng d·ª•ng ng√†y c√†ng nhi·ªÅu...

(150 t·ª´)
```

### Web Scraping (C√≥ Scrape)

```markdown
**N·ªôi dung:**
# Ti√™u ƒë·ªÅ b√†i vi·∫øt

## Gi·ªõi thi·ªáu
C√¥ng ngh·ªá AI ƒëang ph√°t tri·ªÉn nhanh ch√≥ng...

## Chi ti·∫øt
[Full content 2000+ t·ª´]

### Ph·∫ßn 1
...

### Ph·∫ßn 2
...

## K·∫øt lu·∫≠n
...
```

**K·∫øt qu·∫£:**
- ‚úÖ N·ªôi dung ƒë·∫ßy ƒë·ªß 10-20x
- ‚úÖ C·∫•u tr√∫c r√µ r√†ng (headings, lists)
- ‚úÖ Images quality cao
- ‚úÖ Metadata ƒë·∫ßy ƒë·ªß

---

## ‚öôÔ∏è C√ÅCH HO·∫†T ƒê·ªòNG

### 1. Mozilla Readability

**Library:** `@mozilla/readability`  
**Ch·ª©c nƒÉng:** Extract article content t·ª´ HTML (gi·ªëng Reader Mode trong Firefox)

**Algorithm:**
```
1. Remove ads, sidebars, navigation
2. Identify main article container
3. Extract title, author, content
4. Clean up formatting
5. Return clean HTML
```

### 2. HTML ‚Üí Markdown Conversion

**Library:** `turndown`  
**Ch·ª©c nƒÉng:** Convert HTML sang Markdown

**Features:**
- ‚úÖ Headings (H1-H6)
- ‚úÖ Lists (ul, ol)
- ‚úÖ Links, images
- ‚úÖ Bold, italic
- ‚úÖ Code blocks
- ‚úÖ Tables (basic)

### 3. Image Extraction

**Priority:**
```
1. Open Graph image (og:image)
2. Twitter Card image (twitter:image)
3. First article image
4. First large image (>400x300)
```

---

## üéØ BEST PRACTICES

### 1. Ch·ªçn Feed ph√π h·ª£p

‚úÖ **N√™n scrape:**
- VnExpress, Thanh Ni√™n, Tu·ªïi Tr·∫ª ‚Üí Scrape OK
- B√°o ch√≠ ch√≠nh th·ªëng ‚Üí Usually works
- Blog c√° nh√¢n ‚Üí Hit or miss

‚ùå **Kh√¥ng n√™n scrape:**
- Paywall sites (Bloomberg, WSJ)
- Sites c√≥ CAPTCHA
- Sites block bots
- Sites c√≥ anti-scraping

### 2. Test tr∆∞·ªõc khi d√πng

**Test 1 feed tr∆∞·ªõc:**
1. Th√™m feed m·ªõi
2. B·∫≠t scraping
3. Fetch ‚Üí Xem k·∫øt qu·∫£
4. N·∫øu OK ‚Üí D√πng cho t·∫•t c·∫£ feeds

### 3. Monitor performance

**Check logs:**
```
üï∑Ô∏è Scraping URL: https://...
‚úÖ Used scraped content (2500 chars)
```

**N·∫øu th·∫•y:**
```
‚ö†Ô∏è Failed to scrape article: timeout
```
‚Üí Site c√≥ th·ªÉ block ho·∫∑c ch·∫≠m

### 4. Fallback

**Scraping fail ‚Üí D√πng RSS content:**
```
Scraping error ‚Üí Log warning ‚Üí Continue with RSS excerpt
```

Kh√¥ng bao gi·ªù fail to√†n b·ªô v√¨ scraping l·ªói!

---

## üêõ TROUBLESHOOTING

### 1. Scraping qu√° ch·∫≠m

**Nguy√™n nh√¢n:**
- Site ch·∫≠m
- Network ch·∫≠m
- Timeout

**Gi·∫£i ph√°p:**
```typescript
// lib/utils/scraper.ts
signal: AbortSignal.timeout(15000), // TƒÉng t·ª´ 10s ‚Üí 15s
```

### 2. N·ªôi dung b·ªã c·∫Øt/thi·∫øu

**Nguy√™n nh√¢n:**
- Site d√πng JavaScript ƒë·ªÉ load content
- Readability kh√¥ng detect ƒë∆∞·ª£c article

**Gi·∫£i ph√°p:**
- D√πng Puppeteer (headless browser) - n·∫∑ng h∆°n
- Ho·∫∑c edit th·ªß c√¥ng sau khi import

### 3. Image kh√¥ng load

**Nguy√™n nh√¢n:**
- Image b·ªã hotlink protection
- Relative URL kh√¥ng convert ƒë√∫ng

**Gi·∫£i ph√°p:**
```typescript
// ƒê√£ implement: Convert relative ‚Üí absolute URL
new URL(imgSrc, url).href
```

### 4. B·ªã block/rate limited

**Tri·ªáu ch·ª©ng:**
```
Failed to fetch: 403 Forbidden
Failed to fetch: 429 Too Many Requests
```

**Gi·∫£i ph√°p:**
- Gi·∫£m s·ªë l∆∞·ª£ng b√†i fetch (10 ‚Üí 5)
- Th√™m delay gi·ªØa c√°c requests
- Rotate User-Agent

### 5. Charset encoding l·ªói

**Tri·ªáu ch·ª©ng:** Ti·∫øng Vi·ªát b·ªã l·ªói font (√É¬°, √É¬©...)

**Gi·∫£i ph√°p:**
```typescript
const html = await response.text(); // Auto-detect encoding
```

---

## üîß CONFIGURATION

### Timeout

**File:** `lib/utils/scraper.ts`

```typescript
// Line ~30
signal: AbortSignal.timeout(15000), // 15 seconds
```

**Khuy·∫øn ngh·ªã:** 10-20s

### User Agent

**File:** `lib/utils/scraper.ts`

```typescript
// Line ~28
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...'
```

**Tip:** Rotate nhi·ªÅu user agents ƒë·ªÉ tr√°nh block

### Readability Threshold

**File:** `lib/utils/scraper.ts`

```typescript
// Line ~43
const reader = new Readability(document, {
  charThreshold: 100, // Minimum content length
});
```

**Khuy·∫øn ngh·ªã:** 50-200 chars

---

## üöÄ N√ÇNG CAO

### 1. Th√™m Delay gi·ªØa requests

Tr√°nh hammer server:

```typescript
// app/api/admin/rss/fetch/route.ts
for (const item of rssFeed.items.slice(0, 10)) {
  // ... scraping code ...
  
  // Add delay
  await new Promise(resolve => setTimeout(resolve, 2000)); // 2s
}
```

### 2. Retry logic

Retry n·∫øu scraping fail:

```typescript
async function scrapeWithRetry(url: string, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      return await scrapeFullArticle(url);
    } catch (error) {
      if (i === retries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
}
```

### 3. Puppeteer (JavaScript-heavy sites)

**C√†i ƒë·∫∑t:**
```bash
npm install puppeteer
```

**Code:**
```typescript
import puppeteer from 'puppeteer';

export async function scrapeDynamic(url: string) {
  const browser = await puppeteer.launch({ headless: true });
  const page = await browser.newPage();
  await page.goto(url, { waitUntil: 'networkidle2' });
  const html = await page.content();
  await browser.close();
  
  // Parse with Readability...
}
```

‚ö†Ô∏è **Warning:** Puppeteer r·∫•t n·∫∑ng (~300MB), kh√¥ng khuy·∫øn kh√≠ch tr√™n Vercel serverless.

### 4. Proxy rotation

**N·∫øu b·ªã block IP:**
```typescript
const response = await fetch(url, {
  headers: { ... },
  agent: new HttpsProxyAgent('http://proxy-server:port'),
});
```

---

## üìã CHECKLIST TR∆Ø·ªöC KHI DEPLOY

- [ ] Test scraping v·ªõi √≠t nh·∫•t 3 feeds kh√°c nhau
- [ ] Verify content quality (kh√¥ng b·ªã c·∫Øt, format OK)
- [ ] Check images hi·ªÉn th·ªã ƒë√∫ng
- [ ] Test timeout (kh√¥ng qu√° 30s/b√†i)
- [ ] Monitor Vercel function execution time (<10 minutes)
- [ ] Ensure error handling (kh√¥ng crash n·∫øu scraping fail)
- [ ] Check charset encoding (Ti·∫øng Vi·ªát OK)

---

## ‚öñÔ∏è L∆ØU √ù B·∫¢N QUY·ªÄN

**QUAN TR·ªåNG:**

1. **Web Scraping ‚â† Stealing Content**
   - Lu√¥n ghi r√µ ngu·ªìn
   - Link v·ªÅ b√†i g·ªëc
   - T√¥n tr·ªçng robots.txt

2. **Terms of Service**
   - ƒê·ªçc ToS c·ªßa m·ªói website
   - M·ªôt s·ªë site c·∫•m scraping
   - Respect rate limits

3. **Fair Use**
   - Ch·ªâ scrape cho personal use ho·∫∑c news aggregation
   - Kh√¥ng re-publish to√†n b·ªô n·ªôi dung
   - Th√™m gi√° tr·ªã (commentary, analysis)

4. **Best Practice**
   - Polite scraping (delays, reasonable rate)
   - Cache results (kh√¥ng scrape l·∫°i)
   - Identify yourself (User-Agent)

---

## üìä PERFORMANCE STATS

**Average scraping time:**
```
VnExpress:     5-8s/article   ‚úÖ Fast
Thanh Ni√™n:    6-10s/article  ‚úÖ OK
Tu·ªïi Tr·∫ª:      7-12s/article  ‚úÖ OK
Zing News:     10-15s/article ‚ö†Ô∏è Slow
International: 15-30s/article ‚ö†Ô∏è Very slow
```

**Success rate:**
```
Vietnamese news sites: 85-95% ‚úÖ
International sites:   60-80% ‚ö†Ô∏è
Paywalled sites:       0-10%  ‚ùå
```

**Content quality:**
```
Full article:  90%+ ‚úÖ
Partial:       5-8% ‚ö†Ô∏è
Failed:        2-5% ‚ùå
```

---

**üéâ Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi Web Scraping!**

**üìß Support:** T·∫°o GitHub issue n·∫øu g·∫∑p v·∫•n ƒë·ªÅ.

